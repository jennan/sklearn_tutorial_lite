{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b72207a-86d1-493f-8ccc-5eb5f90cf2b1",
   "metadata": {},
   "source": [
    "# Practice Session: Palmer Penguins dataset\n",
    "\n",
    "In the section, we will practice the steps learned so far on a new dataset: the\n",
    "Palmer Penguins dataset.\n",
    "\n",
    "<img alt=\"penguins\" src=\"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/man/figures/lter_penguins.png\" width=500 />\n",
    "\n",
    "*Artwork by @allison_horst*\n",
    "\n",
    "Data were collected and made available by [Dr. Kristen Gorman](https://www.uaf.edu/cfos/people/faculty/detail/kristen-gorman.php)\n",
    "and the [Palmer Station, Antarctica LTER](https://pal.lternet.edu/), a member of\n",
    "the [Long Term Ecological Research Network](https://lternet.edu/).\n",
    "\n",
    "Data are available by  [CC-0](https://creativecommons.org/share-your-work/public-domain/cc0/)\n",
    "license in accordance with the [Palmer Station LTER Data Policy](http://pal.lternet.edu/data/policies)\n",
    "and the [LTER Data Access Policy for Type I data](https://lternet.edu/data-access-policy/).\n",
    "\n",
    "Here we will use a subset of it, prepared for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cd2af5-7787-47c3-a277-e913307e19c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cfe32f-1061-400f-be92-b3cfbb61d6b8",
   "metadata": {},
   "source": [
    "## Loading and visualizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaab3af-bba1-405f-bcef-5adcb80fd7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from penguins import load_penguins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b76881b-6624-4227-bdae-fe0ee2304c88",
   "metadata": {},
   "source": [
    "First, using the `load_penguins` function, load the data set and explore it.\n",
    "\n",
    "As you do it, answer the following questions:\n",
    "\n",
    "- how many features does it contain?\n",
    "- how many samples?\n",
    "- what is the target variable and how is it encoded?\n",
    "\n",
    "*Note: more information about the culmen measures are available [here](https://allisonhorst.github.io/palmerpenguins/#bill-dimensions).*\n",
    "\n",
    "**Hint: this section is very similar to the [Iris data set exploration in section 02.1](02.1-Machine-Learning-Intro.ipynb#Loading-the-Iris-Data-with-Scikit-Learn).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25500ca-87ed-4acb-abec-71c9e7ccd500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267fe7c4-003f-44eb-a98d-77da9402c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the size of the feature matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0f1b8a-3d43-4b81-a241-0f7eb2dae18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the name of the features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febefc8b-b961-4457-9280-3a12cb587c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce809a5-688c-4755-bd3c-b0c2bb8e03ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and its possible values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e22af8-1ae0-4961-9201-89d8e9b2e0ac",
   "metadata": {},
   "source": [
    "Next, let's have a look at the data and see how the different species are\n",
    "distributed. Create a plot showing two of the dimensions of the dataset.\n",
    "\n",
    "*Bonus: you can create a function and use it in a loop to show all pairs of dimensions.*\n",
    "\n",
    "**Hint: this section is very similar to the [Iris data set exploration in section 02.1](02.1-Machine-Learning-Intro.ipynb#Loading-the-Iris-Data-with-Scikit-Learn).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc305da-6c68-45cf-812f-38a2f1cc134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scatter plot to display two of the dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5055e754-aeed-4526-92e7-4b30eba35650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bonus: plot all pairs of features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0e8ea9-1f87-4063-bc91-9d95ed5f5c35",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Given the nature of the dataset and the target data, what type of machine learning\n",
    "task are we trying to achieve (2 keywords)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93513c0c-55bf-417d-bedd-dadd28c32749",
   "metadata": {},
   "source": [
    "## Fit a baseline model: logistic regression\n",
    "\n",
    "Now that we have loaded and explored the dataset, we can start fitting a first\n",
    "model and measure its performance.\n",
    "\n",
    "Let's start with a `LogisticRegression` model, as follows:\n",
    "\n",
    "1. split the data into a training and test datasets,\n",
    "2. import the `LogisticRegression` class and create the model,\n",
    "3. fit the model to the training dataset,\n",
    "4. generate predictions on the test dataset,\n",
    "5. compute the accuracy score of the model.\n",
    "\n",
    "*Bonus: plot the corresponding confusion matrix.*\n",
    "\n",
    "**Hint: this section is very similar to the [classification on digits example in section 02.2](02.2-Basic-Principles.ipynb#Classification-on-Digits).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2950b1c0-40f5-4ec9-8ace-801a51f3dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset in train / test folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f924418e-0d78-4cc3-9c95-ca4780d00887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the LogisticRegression class, create a model and fit it to training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70718130-0a33-472f-8ff8-98c8ab0747b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict labels on the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a513cd1-a9df-4fe5-92a5-9e7f662a5f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the accuracy score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5459e71-1859-4500-84b7-0220d28f4b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bonus: display the confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0045a8-2c34-4bd9-92c4-885a9bd468c3",
   "metadata": {},
   "source": [
    "To improve the quantification of the model performance, use the `cross_val_score`\n",
    "function to compute 5 folds cross-validation estimation of the model accuracy.\n",
    "\n",
    "**Hint: this section is very similar to the [K-fold Cross-Validation in section 05](05-Validation.ipynb#K-fold-Cross-Validation).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e721c2-a96a-4d26-8307-abc3289a44aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the cross-validated accuracy score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fee761-ea0b-432a-89f7-f02b556f5e6f",
   "metadata": {},
   "source": [
    "### Bonus questions\n",
    "\n",
    "- Use the `make_pipeline` function in combination with the `StandardScaler`\n",
    "  preprocessor to fit a logistic regression model with input normalization.\n",
    "- Use the `cross_val_predict` function to generate the confusion matrix for each\n",
    "  input data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca63e89-5bdc-4c75-beb0-2aaa90cc1c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a composite model using StandardScaler and LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16829de-a4dc-44ae-83e2-6eb0f501b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a confusion matrix for cross-validated predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf86025-b7a3-4daa-a04f-e850bbf9ad8c",
   "metadata": {},
   "source": [
    "## Fit a random forest model\n",
    "\n",
    "Now that we have a first linear model fitted, we can explore other models and\n",
    "compare the cross-validated performances.\n",
    "\n",
    "Fit a `RandomForestClassifier` and compute its cross-validated accuracy score.\n",
    "\n",
    "Does it perform better than the logistic regression model?\n",
    "\n",
    "**Hint: this model has been used a similar way in the [Random Forest for Classifying Digits in section 03.2](03.2-Regression-Forests.ipynb#Example:-Random-Forest-for-Classifying-Digits).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b730cb-86cb-40af-a0bd-76df8c102c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import, create and fit a RandomForestClassifier model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db54016c-9c82-4697-9356-a319789e60d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the cross-validated accuracy score\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 (gimkl-2022a)",
   "language": "python",
   "name": "python3105-gimkl-2022a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
